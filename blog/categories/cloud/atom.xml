<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cloud | heXoughts - arco's braindumps & musings]]></title>
  <link href="http://arcolife.github.io/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://arcolife.github.io/"/>
  <updated>2020-02-07T08:21:20+05:30</updated>
  <id>http://arcolife.github.io/</id>
  <author>
    <name><![CDATA[Archit Sharma]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Performance Engineering TILs - Part 1]]></title>
    <link href="http://arcolife.github.io/blog/2017/03/02/performance-engineering-tils-part-1/"/>
    <updated>2017-03-02T17:00:16+05:30</updated>
    <id>http://arcolife.github.io/blog/2017/03/02/performance-engineering-tils-part-1</id>
    <content type="html"><![CDATA[<h2>On Scale tests</h2>

<h4>..on distributed systems, in companies with a global, collaborative and distributed workplace setup</h4>

<p>Before running a scale test, make sure to have the following items checked off your list:</p>

<ol>
<li>Is churn on product integrations, enough to simulate production environment?</li>
<li>During the tests, is the product going to run with defaults? Is this about baselining with defaults or are we going to let the system bleed while increasing throughputs?</li>
<li>Do you have exact expectations noted down prior to automating? (per se, monitoring enough parameters in the right way. This includes Telemetry, Logs and Configurations per iteration.)</li>
</ol>


<!--more-->


<p>   An example of this, from a distributed systems application framework could be:</p>

<ul>
<li> Time spent collecting the data as well as size of data v/s Time it took to be committed to the db &ndash; per se, fetch time/volume and db time.</li>
<li><p> Size of data transferred over network for a single workload (and for all workloads/functionalities associated with that application)</p></li>
<li><p>List of parameters not to be changed? CPU/RAM/Memory/Disk/partitions/Network bandwidth/OS/Installed Packages/Tuning parameters/&hellip;.</p></li>
<li>Do you have tuning recommendations for the product, prior to testing?</li>
<li>Do you have enough debugging skills on the product, to begin with? (extension: Have you solved enough bugs yet?). If not, it&rsquo;s good to have some consultation on this as it helps with forming theories on conclusions.</li>
<li>Do you have the lab environment&rsquo;s hardware availability dates in a flexible time range? (keeping potential bottlenecks in mind)</li>
</ul>


<p>I have been reading Brendon Gregg&rsquo;s <a href="http://www.brendangregg.com/sysperfbook.html">&ldquo;Systems Performance: Enterprise and the Cloud&rdquo;</a> and am inclined to finish this soon. All of the points above, have probably been already covered in detail, in that book.</p>
]]></content>
  </entry>
  
</feed>
